{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from data.load import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmap\n",
    "import matplotlib as mpl\n",
    "\n",
    "stat_file_name = 'df_metrics.csv'\n",
    "MEAS_PATH = 'results/13th_run/'\n",
    "DATA_PATH = '/media/balint/Backup1/data/1d-class-datasets/interpolated-7th-run/'\n",
    "TIMES = [30, 60, 90, 120, 150] # sorted(os.listdir(MEAS_PATH))\n",
    "MEAS_TYPES = [f for f in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, f))]\n",
    "# NETWORKS = os.listdir(os.path.join(MEAS_PATH, MEAS_TYPES[0], str(TIMES[0]), )) # ['inception', 'mcdcnn', 'cnn']\n",
    "# VAL_FOLDERS = sorted([ n for n in os.listdir(os.path.join(MEAS_PATH, MEAS_TYPES[0], str(TIMES[0]), NETWORKS[0])) if 'cv' in n])\n",
    "# DATA_FOLDERS = sorted([os.path.join(DATA_PATH) for t in MEAS_TYPES])\n",
    "\n",
    "\n",
    "# cm = cmap.get_cmap('Set1', 7)\n",
    "cm = ['#32CD32','#00bfff', '#ff0000','#FFA500','#9932cc','#964B00','#808080']\n",
    "names = {\n",
    "    'cnn': 'CNN',\n",
    "    'mlp': 'MLP',\n",
    "    'mcdcnn': 'MCDCNN',\n",
    "    'fcn': 'FCN',\n",
    "    'resnet': 'ResNet',\n",
    "    'inception': 'Inception'\n",
    "}\n",
    "\n",
    "cell_types = {\n",
    "    'preo':'MC3T3-E1',\n",
    "    'hela':'HeLa',\n",
    "    'mcf7':'MCF-7',\n",
    "    'mdamb231':'MDA MB 231',\n",
    "    'lclc':'LCLC-103H',\n",
    "    'breastcancer':'Breast cancer'\n",
    "}\n",
    "\n",
    "def format_cell_types(st):\n",
    "    selected_types = sorted([ cell_types[tp] for tp in st.split('-')])\n",
    "    return ' | '.join(selected_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for tp in MEAS_TYPES:\n",
    "    # cnts = []\n",
    "    types = { cell_types[t]: [] for t in tp.split('-')}\n",
    "    for time in TIMES:\n",
    "        pth = os.path.join(DATA_PATH, tp,str(time))\n",
    "        if os.path.exists(pth):\n",
    "            counts = {}\n",
    "            X_train, y_train, X_test, y_test, (names, tags), scaler = load_dataset(pth, False, False)\n",
    "            data = np.vstack([X_train, X_test])\n",
    "            labels = np.concatenate([y_train, y_test])\n",
    "            el, cnt = np.unique(labels, return_counts=True)\n",
    "            # print(el, cnt, names, tags)\n",
    "            for n, l in zip(names, tags):\n",
    "                counts[n] = cnt[l]\n",
    "                types[cell_types[n]].append(str(cnt[l]))\n",
    "            # print(counts)\n",
    "            # print(tp, time, counts)\n",
    "            # cnts.append(cnt[0])\n",
    "            \n",
    "        # print(tp, cnts)\n",
    "    stats[format_cell_types(tp)] = { cell_types[t]: '|'.join(types[cell_types[t]]) for t in tp.split('-')}\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'cell_counts.json'), 'w') as fp:\n",
    "    json.dump(stats, \n",
    "              fp, \n",
    "              sort_keys=False,\n",
    "              indent=4,\n",
    "              separators=(',', ': ')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = {}\n",
    "\n",
    "for tp in MEAS_TYPES:\n",
    "    if not tp in stats_dict:\n",
    "        stats_dict[tp] = {}\n",
    "    for nw in NETWORKS:\n",
    "        if not nw in stats_dict[tp]:\n",
    "            stats_dict[tp][nw] = {}\n",
    "        for tm in TIMES:    \n",
    "            precision, accuracy, recall, duration = [], [], [], []\n",
    "            for fd in VAL_FOLDERS:\n",
    "                df = pd.read_csv(os.path.join(MEAS_PATH, tm, tp, nw, 'train-test_itr_0', fd, stat_file_name))\n",
    "                precision.append(df.precision.item())\n",
    "                accuracy.append(df.accuracy.item())\n",
    "                recall.append(df.recall.item())\n",
    "                duration.append(df.duration.item())\n",
    "            stats_dict[tp][nw][tm] = {\n",
    "                'precision': [np.round(np.mean(precision), 2), np.round(np.std(precision), 2), np.round(np.max(precision), 2)],\n",
    "                'accuracy': [np.round(np.mean(accuracy), 2), np.round(np.std(accuracy), 2), np.round(np.max(accuracy), 2)],\n",
    "                'recall': [np.round(np.mean(recall), 2), np.round(np.std(recall), 2), np.round(np.max(recall), 2)],\n",
    "                'duration': [np.round(np.mean(duration), 2), np.round(np.std(duration), 2), np.round(np.max(duration), 2)]\n",
    "            }\n",
    "                    \n",
    "                \n",
    "                    \n",
    "with open('stats.json', 'w') as fp:\n",
    "    json.dump(stats_dict, \n",
    "              fp, \n",
    "              sort_keys=False,\n",
    "              indent=4,\n",
    "              separators=(',', ': ')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = {}\n",
    "for nw in NETWORKS:\n",
    "    if not nw in stats_dict:\n",
    "        stats_dict[nw] = {}\n",
    "    for tp in MEAS_TYPES:\n",
    "        if not tp in stats_dict[nw]:\n",
    "            stats_dict[nw][tp] = {}\n",
    "        l = []\n",
    "        for tm in TIMES:    \n",
    "            precision, accuracy, recall, duration = [], [], [], []\n",
    "            for fd in VAL_FOLDERS:\n",
    "                df = pd.read_csv(os.path.join(MEAS_PATH, tm, tp, nw, 'train-test_itr_0', fd, stat_file_name))\n",
    "                precision.append(df.precision.item())\n",
    "                accuracy.append(df.accuracy.item())\n",
    "                recall.append(df.recall.item())\n",
    "                duration.append(df.duration.item())\n",
    "            stats_dict[nw][tp][tm] = {\n",
    "                # 'precision': [np.round(np.mean(precision), 2), np.round(np.std(precision), 2), np.round(np.max(precision), 2)],\n",
    "                'accuracy': [np.round(np.mean(accuracy), 2), np.round(np.std(accuracy), 2), np.round(np.max(accuracy), 2)],\n",
    "                # 'recall': [np.round(np.mean(recall), 2), np.round(np.std(recall), 2), np.round(np.max(recall), 2)],\n",
    "                # 'duration': [np.round(np.mean(duration), 2), np.round(np.std(duration), 2), np.round(np.max(duration), 2)]\n",
    "            }\n",
    "            l.append([precision, accuracy, recall, duration])\n",
    "        stats_dict[nw][tp] = [np.round(np.mean(e[1]), 2) for e in l]\n",
    "        # {\n",
    "        #     # 'precision': [[np.mean(e[0]), np.std(e[0]), np.max(e[0])] for e in l],\n",
    "        #     'accuracy': [np.mean(e[1]) for e in l],\n",
    "        #     # 'recall': [[np.mean(e[2]), np.std(e[2]), np.max(e[2])] for e in l],\n",
    "        #     # 'duration': [[np.mean(e[3]), np.std(e[3]), np.max(e[3])] for e in l]\n",
    "            \n",
    "        #     # 'precision': np.mean([np.mean(e[0]) for e in l]),\n",
    "        #     # 'accuracy': np.mean([np.mean(e[1]) for e in l]),\n",
    "        #     # 'recall': np.mean([np.mean(e[2]) for e in l]),\n",
    "        #     # # 'duration': np.mean([np.mean(e[3]) for e in l]),\n",
    "        #     # 'best_time': TIMES[np.argmax([np.mean(e[1]) for e in l])]\n",
    "        # }\n",
    "                    \n",
    "                \n",
    "                    \n",
    "# with open('stats.json', 'w') as fp:\n",
    "#     json.dump(stats_dict, \n",
    "#               fp, \n",
    "#               sort_keys=False,\n",
    "#               indent=4,\n",
    "#               separators=(',', ': ')\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(16,8))\n",
    "\n",
    "for n, (key, value) in enumerate(stats_dict.items()):\n",
    "    for m, (m_key, m_value) in enumerate(value.items()):\n",
    "        ax[n//3, n%3].plot(m_value, c=cm[m], label=format_cell_types(m_key) if n == 0 else None)\n",
    "        ax[n//3, n%3].plot(m_value, 'o', c=cm[m])\n",
    "        \n",
    "    ax[n//3, n%3].set_title(names[key],fontsize=12)\n",
    "    ax[n//3, n%3].set_ylim((0.3, 1))\n",
    "    ax[n//3, n%3].set_xticklabels([i*0.5 for i in range(6)])\n",
    "    if n > 2:\n",
    "        ax[n//3, n%3].set_xlabel(\"Time(hrs)\",fontsize=12)\n",
    "    if n == 0 or n == 3:\n",
    "        ax[n//3, n%3].set_ylabel(\"Accuracy\",fontsize=12)\n",
    "    if n == 0:\n",
    "        ax[n//3, n%3].legend(ncol=3, bbox_to_anchor=(0.87, 0.05),\n",
    "                bbox_transform=fig.transFigure)\n",
    "plt.savefig('network-compare.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ['resnet', 'inception', 'mcdcnn']\n",
    "stats_dict = {}\n",
    "for nw in networks:\n",
    "    if not nw in stats_dict:\n",
    "        stats_dict[nw] = {}\n",
    "    for tp in MEAS_TYPES:\n",
    "        if not tp in stats_dict[nw]:\n",
    "            stats_dict[nw][tp] = {}\n",
    "        l = []\n",
    "        for tm in ['1hrs']:    \n",
    "            precision, accuracy, recall, duration = [], [], [], []\n",
    "            for fd in VAL_FOLDERS:\n",
    "                df = pd.read_csv(os.path.join(MEAS_PATH, tm, tp, nw, 'train-test_itr_0', fd, stat_file_name))\n",
    "                precision.append(df.precision.item())\n",
    "                accuracy.append(df.accuracy.item())\n",
    "                recall.append(df.recall.item())\n",
    "                duration.append(df.duration.item())\n",
    "            stats_dict[nw][tp][tm] = {\n",
    "                # 'precision': [np.round(np.mean(precision), 2), np.round(np.std(precision), 2), np.round(np.max(precision), 2)],\n",
    "                'accuracy': [np.round(np.mean(accuracy), 2), np.round(np.std(accuracy), 2), np.round(np.max(accuracy), 2)],\n",
    "                # 'recall': [np.round(np.mean(recall), 2), np.round(np.std(recall), 2), np.round(np.max(recall), 2)],\n",
    "                # 'duration': [np.round(np.mean(duration), 2), np.round(np.std(duration), 2), np.round(np.max(duration), 2)]\n",
    "            }\n",
    "            l.append([precision, accuracy, recall, duration])\n",
    "        e = l[0]\n",
    "        stats_dict[nw][tp] = {\n",
    "                'precision': [np.round(np.mean(e[0]),2), np.round(np.std(e[0]),2)],\n",
    "                'accuracy': [np.round(np.mean(e[1]),2), np.round(np.std(e[1]),2)],\n",
    "                'recall': [np.round(np.mean(e[2]),2), np.round(np.std(e[2]),2)],\n",
    "                # 'duration': [[np.mean(e[3]), np.std(e[3]), np.max(e[3])] for e in l]\n",
    "            }\n",
    "                    \n",
    "                \n",
    "                    \n",
    "with open('stats.json', 'w') as fp:\n",
    "    json.dump(stats_dict, \n",
    "              fp, \n",
    "              sort_keys=False,\n",
    "              indent=4,\n",
    "              separators=(',', ': ')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list = []\n",
    "\n",
    "for tp in MEAS_TYPES:\n",
    "    for nw in networks:\n",
    "       row = [format_cell_types(tp), names[nw], stats_dict[nw][tp]['precision'],stats_dict[nw][tp]['accuracy'],stats_dict[nw][tp]['recall']] \n",
    "       stats_list.append(row)\n",
    "       \n",
    "df = pd.DataFrame(stats_list, columns=['setup', 'network', 'precision', 'accuracy', 'recall'])\n",
    "df.to_excel('stats.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[nw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanobio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
