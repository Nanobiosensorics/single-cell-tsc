{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "DATA_PATH = '../cell_data/data/lognorm-evaluation/eval/max/fibronectin_full/'\n",
    "RESULT_PATH = './results/2nd_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'cnn', 'path': './results/2nd_run/cnn'},\n",
       "  {'name': 'mlp', 'path': './results/2nd_run/mlp'},\n",
       "  {'name': 'encoder', 'path': './results/2nd_run/encoder'},\n",
       "  {'name': 'mcdcnn', 'path': './results/2nd_run/mcdcnn'},\n",
       "  {'name': 'fcn', 'path': './results/2nd_run/fcn'},\n",
       "  {'name': 'resnet', 'path': './results/2nd_run/resnet'},\n",
       "  {'name': 'inception', 'path': './results/2nd_run/inception'}],\n",
       " [{'name': 'cnn',\n",
       "   'path': './results/2nd_run/cnn',\n",
       "   'experiments': ['./results/2nd_run/cnn/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/cnn/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/cnn/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/cnn/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/cnn/fibronectin_full_itr_4']},\n",
       "  {'name': 'mlp',\n",
       "   'path': './results/2nd_run/mlp',\n",
       "   'experiments': ['./results/2nd_run/mlp/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/mlp/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/mlp/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/mlp/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/mlp/fibronectin_full_itr_4']},\n",
       "  {'name': 'encoder',\n",
       "   'path': './results/2nd_run/encoder',\n",
       "   'experiments': ['./results/2nd_run/encoder/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/encoder/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/encoder/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/encoder/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/encoder/fibronectin_full_itr_4']},\n",
       "  {'name': 'mcdcnn',\n",
       "   'path': './results/2nd_run/mcdcnn',\n",
       "   'experiments': ['./results/2nd_run/mcdcnn/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/mcdcnn/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/mcdcnn/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/mcdcnn/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/mcdcnn/fibronectin_full_itr_4']},\n",
       "  {'name': 'fcn',\n",
       "   'path': './results/2nd_run/fcn',\n",
       "   'experiments': ['./results/2nd_run/fcn/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/fcn/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/fcn/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/fcn/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/fcn/fibronectin_full_itr_4']},\n",
       "  {'name': 'resnet',\n",
       "   'path': './results/2nd_run/resnet',\n",
       "   'experiments': ['./results/2nd_run/resnet/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/resnet/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/resnet/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/resnet/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/resnet/fibronectin_full_itr_4']},\n",
       "  {'name': 'inception',\n",
       "   'path': './results/2nd_run/inception',\n",
       "   'experiments': ['./results/2nd_run/inception/fibronectin_full_itr_0',\n",
       "    './results/2nd_run/inception/fibronectin_full_itr_1',\n",
       "    './results/2nd_run/inception/fibronectin_full_itr_2',\n",
       "    './results/2nd_run/inception/fibronectin_full_itr_3',\n",
       "    './results/2nd_run/inception/fibronectin_full_itr_4']}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_paths = [ { 'name': name, 'path': os.path.join(RESULT_PATH, name)} \n",
    "                for name in os.listdir(RESULT_PATH) if os.path.isdir(os.path.join(RESULT_PATH, name))]\n",
    "# experiments = {result['path']: [os.path.join(result['path'], name) for name in os.listdir(result['path'])] for result in result_paths}\n",
    "experiments = [ {'name': result['name'],'path': result['path'], \n",
    "                 'experiments': sorted([os.path.join(result['path'], name) \n",
    "                                        for name in os.listdir(result['path']) if os.path.isdir(os.path.join(result['path'], name))])} for result in result_paths]\n",
    "result_paths, experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = experiments[0]\n",
    "# fig, ax = plt.subplots(2,2, figsize=(15,8))\n",
    "# for m, experiment in enumerate(obj['experiments']):\n",
    "#     exp_hist = pd.read_csv(os.path.join(experiment, 'history.csv'))\n",
    "#     ax[0,0].plot(exp_hist.loss)\n",
    "#     ax[0,1].plot(exp_hist.val_loss)\n",
    "#     ax[1,0].plot(exp_hist.accuracy)\n",
    "#     ax[1,1].plot(exp_hist.val_accuracy)\n",
    "#     ax[1,0].set_ylim((0,1))\n",
    "#     ax[1,1].set_ylim((0,1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(func):\n",
    "    def wrap(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        \n",
    "        print('Generated', args[0], round(end-start, 2), 's')\n",
    "        return result\n",
    "    return wrap\n",
    "\n",
    "def get_max_acc_experiment(experiment):\n",
    "    mx_idx = 0\n",
    "    max_accs = 0\n",
    "    for n, exp in enumerate(experiment['experiments']):\n",
    "        exp_hist = pd.read_csv(os.path.join(exp, 'history.csv'))\n",
    "        mx = max(exp_hist.val_accuracy)\n",
    "        if max_accs < mx:\n",
    "            mx_idx = n\n",
    "            max_accs = mx\n",
    "    return mx_idx\n",
    "\n",
    "def get_predictions(experiment, labels):\n",
    "    preds = pd.read_csv(os.path.join(experiment, 'true-pred-values.csv'))\n",
    "    y_pred = np.array(preds.pred)\n",
    "    pred_labels = [labels[y_pred[n]] for n in range(y_pred.shape[0])]\n",
    "    return y_pred, pred_labels\n",
    "\n",
    "def get_test(path, labels):\n",
    "    x_test = np.load(os.path.join(path, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(path, 'y_test.npy'))\n",
    "    test_labels = [labels[y_test[n]] for n in range(y_test.shape[0])]\n",
    "    return x_test, y_test, test_labels\n",
    "\n",
    "def get_dictionary(path):\n",
    "    dictionary = pd.read_csv(os.path.join(path, 'dictionary.csv'))\n",
    "    labels = list(dictionary.iloc[:, 0])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def generate_loss_acc_plot(filename, experiment):\n",
    "    fig, ax = plt.subplots(2,2, figsize=(15,8))\n",
    "    plt.suptitle(experiment['name'])\n",
    "    ax[0,0].set_title(\"Trn loss\")\n",
    "    ax[0,1].set_title(\"Val loss\")\n",
    "    ax[1,0].set_title(\"Trn Accuracy\")\n",
    "    ax[1,1].set_title(\"Val Accuracy\")\n",
    "    for n, exp in enumerate(experiment['experiments']):\n",
    "        exp_hist = pd.read_csv(os.path.join(exp, 'history.csv'))\n",
    "        ax[0,0].plot(exp_hist.loss, label=n)\n",
    "        ax[0,1].plot(exp_hist.val_loss, label=n)\n",
    "        ax[1,0].plot(exp_hist.accuracy, label=n)\n",
    "        ax[1,1].plot(exp_hist.val_accuracy, label=n)\n",
    "    ax[0,0].legend()\n",
    "    ax[0,1].legend()\n",
    "    ax[1,0].legend()\n",
    "    ax[1,1].legend()\n",
    "    ax[1,0].set_ylim((0,1))\n",
    "    ax[1,1].set_ylim((0,1))\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "@log\n",
    "def generate_tr_tst_plot(filename, experiments):   \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "    ax[0].set_title(\"Trn Accuracy\")\n",
    "    ax[1].set_title(\"Val Accuracy\")\n",
    "    for exp in experiments:\n",
    "    #     if exp['name'] not in ['resnet', 'fcn']: \n",
    "        mx_idx = get_max_acc_experiment(exp)\n",
    "        exp_hist = pd.read_csv(os.path.join(exp['experiments'][mx_idx], 'history.csv'))\n",
    "        ax[0].plot(exp_hist.accuracy, label=exp['name'], alpha=.5)\n",
    "        ax[1].plot(exp_hist.val_accuracy, label=exp['name'], alpha=.5)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[0].set_xlim((0, 400))\n",
    "    ax[1].set_xlim((0, 400))\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "@log\n",
    "def generate_tst_pred_plot(filename, experiment, x_test, y_test, labels):\n",
    "    label_count = len(labels)\n",
    "    cmap = mpl.cm.get_cmap('Set1', label_count)\n",
    "    for n, exp in enumerate(experiment['experiments']):\n",
    "        y_pred, _ = get_predictions(exp, labels)\n",
    "        fig, ax = plt.subplots(5,1, figsize=(15,50))\n",
    "        fig.suptitle(\"Test predictions\")\n",
    "        for i in range(label_count):\n",
    "            for j in range(label_count):\n",
    "                ax[i].plot([], c=cmap(j), label=labels[j])\n",
    "            ax[i].legend()\n",
    "            ax[i].set_title(''.join([labels[i], '-predictions']))\n",
    "\n",
    "        for n in range(x_test.shape[0]):\n",
    "            ax[y_test[n]].plot(x_test[n,:], c=cmap(y_pred[n]))\n",
    "        plt.savefig(os.path.join(exp, 'tst-predictions-types.png'))\n",
    "        plt.close()\n",
    "\n",
    "@log\n",
    "def generate_preds_plot(filename, experiment, x_test, y_test, labels):\n",
    "    label_count = len(labels)\n",
    "    cmap = ['r', 'g']\n",
    "    for n, exp in enumerate(experiment['experiments']):\n",
    "        y_pred, _ = get_predictions(exp, labels)\n",
    "        fig, ax = plt.subplots(5,1, figsize=(15,50))\n",
    "        for i in range(label_count):\n",
    "            for n, label in enumerate(['false', 'true']):\n",
    "                ax[i].plot([], c=cmap[n], label=label)\n",
    "            ax[i].legend()\n",
    "            ax[i].set_title(''.join([labels[i], '_predictions']))\n",
    "                \n",
    "        for n in range(x_test.shape[0]):\n",
    "            ax[y_test[n]].plot(x_test[n, :], c=cmap[int(y_pred[n] == y_test[n])])\n",
    "        plt.savefig(os.path.join(exp, 'tst-predictions.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating loss-accuracy plots\n",
      "Generated ./results/2nd_run/cnn/cnn-tr-tst-metrics.png 0.52 s\n",
      "Generated ./results/2nd_run/mlp/mlp-tr-tst-metrics.png 0.54 s\n",
      "Generated ./results/2nd_run/encoder/encoder-tr-tst-metrics.png 0.44 s\n",
      "Generated ./results/2nd_run/mcdcnn/mcdcnn-tr-tst-metrics.png 0.47 s\n",
      "Generated ./results/2nd_run/fcn/fcn-tr-tst-metrics.png 0.48 s\n",
      "Generated ./results/2nd_run/resnet/resnet-tr-tst-metrics.png 0.49 s\n",
      "Generated ./results/2nd_run/inception/inception-tr-tst-metrics.png 0.47 s\n",
      "Generating total train-test metrics plot\n",
      "Generated ./results/2nd_run/tr-tst-metrics.png 0.38 s\n",
      "Generating test prediction types plots\n",
      "Generated ./results/2nd_run/cnn 14.3 s\n",
      "Generated ./results/2nd_run/mlp 19.1 s\n",
      "Generated ./results/2nd_run/encoder 14.47 s\n",
      "Generated ./results/2nd_run/mcdcnn 14.64 s\n",
      "Generated ./results/2nd_run/fcn 14.66 s\n",
      "Generated ./results/2nd_run/resnet 14.82 s\n",
      "Generated ./results/2nd_run/inception 14.1 s\n",
      "Generating test prediction plots\n",
      "Generated ./results/2nd_run/cnn 14.45 s\n",
      "Generated ./results/2nd_run/mlp 13.65 s\n",
      "Generated ./results/2nd_run/encoder 14.61 s\n",
      "Generated ./results/2nd_run/mcdcnn 13.69 s\n",
      "Generated ./results/2nd_run/fcn 14.82 s\n",
      "Generated ./results/2nd_run/resnet 13.7 s\n",
      "Generated ./results/2nd_run/inception 13.6 s\n"
     ]
    }
   ],
   "source": [
    "# Loss-Accuracy plots\n",
    "print(\"Generating loss-accuracy plots\")\n",
    "for experiment in experiments:\n",
    "    generate_loss_acc_plot(os.path.join(experiment['path'], experiment['name']+'-tr-tst-metrics.png'), experiment)\n",
    "# Total train-test metrics\n",
    "print(\"Generating total train-test metrics plot\")\n",
    "generate_tr_tst_plot(os.path.join(RESULT_PATH, 'tr-tst-metrics.png'), experiments)\n",
    "\n",
    "labels = get_dictionary(DATA_PATH)\n",
    "x_test, y_test, test_labels = get_test(DATA_PATH, labels)\n",
    "# successfull_pred = y_test == y_pred\n",
    "\n",
    "# Test prediction types plots\n",
    "print(\"Generating test prediction types plots\")\n",
    "for experiment in experiments:\n",
    "    generate_tst_pred_plot(experiment['path'], experiment, x_test, y_test, labels)\n",
    "\n",
    "\n",
    "print(\"Generating test prediction plots\")\n",
    "for experiment in experiments:\n",
    "    generate_preds_plot(experiment['path'], experiment, x_test, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiments[0]['experiments'][0]\n",
    "preds = pd.read_csv(os.path.join(exp, 'true-pred-values.csv'))\n",
    "y_pred = np.array(preds.pred)\n",
    "x_test = np.load(os.path.join(DATA_PATH, 'X_test.npy'))\n",
    "y_test = np.load(os.path.join(DATA_PATH, 'y_test.npy'))\n",
    "dictionary = pd.read_csv(os.path.join(DATA_PATH, 'dictionary.csv'))\n",
    "labels = list(dictionary.iloc[:, 0])\n",
    "label_count = len(labels)\n",
    "pred_labels = [labels[y_pred[n]] for n in range(y_pred.shape[0])]\n",
    "test_labels = [labels[y_test[n]] for n in range(y_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(test_labels, pred_labels, labels=labels, normalize='true')\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "# plt.figure()\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(x_test[:, -1], bins=100, density=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(y_pred[1] == y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fd3bbdfa923658c6d5e5671aecb15a5f4bacb63005c242ea558ac2164f2eb45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
